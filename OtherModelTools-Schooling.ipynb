{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison and Feature Selection\n",
    "\n",
    "This notebook provides supervised learning tools to understand associations between the target variable and the predictors. The supporting Python code is in ModelTools.py. Many of the functions have additional arguments that are defaulted. For more details look through the code. Also add any functions you find useful.\n",
    "\n",
    "# Outline \n",
    "\n",
    "<!-- MarkdownTOC autolink=true autoanchor=true bracket=round -->\n",
    "\n",
    "- [Part One - Univariate Analysis](#part-one---univariate-analysis)\n",
    "    - [Load Data and Specify Variables](#load-data-and-specify-variables)\n",
    "    - [One Hot Encode Categorical Variables](#one-hot-encode-categorical-variables)\n",
    "    - [Linear Univariate Analysis](#linear-univariate-analysis)\n",
    "    - [Random Forest Univariate Analysis](#random-forest-univariate-analysis)\n",
    "    - [Gradient Boosting Univariate Analysis](#gradient-boosting-univariate-analysis)\n",
    "- [Part Two - Model Comparison  --  Done in different workbook.]\n",
    "- [Part Three - Variable Selection](#part-three---variable-selection)\n",
    "    - [Random Forest](#random-forest)\n",
    "    - [Gradient Boosting](#gradient-boosting)\n",
    "\n",
    "<!-- MarkdownTOC -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"part-one---univariate-analysis\"></a>\n",
    "# Part One - Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"load-data-and-specify-variables\"></a>\n",
    "## Load Data and Specify Variables\n",
    "\n",
    "In this section we will load our dataset, print the index of each feature and then specify which variables are predictors, target, controls (optional), and weight (optional). For variables with null values, null_value_cleanup will create IS_NULL indicator variables. If you prefer another method of dealing with missing values, like imputing values (e.g. mean, median, mode), write a function to do it, put it in EDATools, and call it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/homer/anaconda4/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 smsa66\n",
      "1 smsa76\n",
      "2 nearc2\n",
      "3 nearc4\n",
      "4 nearc4a\n",
      "5 nearc4b\n",
      "6 ed76\n",
      "7 ed66\n",
      "8 age76\n",
      "9 daded\n",
      "10 nodaded\n",
      "11 momed\n",
      "12 nomomed\n",
      "13 momdad14\n",
      "14 sinmom14\n",
      "15 step14\n",
      "16 south66\n",
      "17 south76\n",
      "18 lwage76\n",
      "19 famed\n",
      "20 black\n",
      "21 wage76\n",
      "22 enroll76\n",
      "23 kww\n",
      "24 kww_ISNULL\n",
      "25 iqscore\n",
      "26 iqscore_ISNULL\n",
      "27 mar76\n",
      "28 libcrd14\n",
      "29 exp76\n"
     ]
    }
   ],
   "source": [
    "import EDATools\n",
    "import ModelTools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dataset = sm.datasets.get_rdataset(\"Schooling\", \"Ecdat\").data\n",
    "\n",
    "EDATools.null_value_cleanup(dataset)\n",
    "\n",
    "# Print the index of each feature.\n",
    "for i, col in enumerate(dataset.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set index of predictors, target, controls, weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = np.array([2,3,6,7,8,9,10,11,12,14,15,20,23,25,27,28,29])\n",
    "numeric_cat_index = np.array([2,3,10,12,14,15,20,27,28])\n",
    "target = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"one-hot-encode-categorical-variables\"></a>\n",
    "## One Hot Encode Categorical Variables\n",
    "\n",
    "For the purpose of modeling we will one-hot encode each categorical variable. We will also re-name our features so that categorical variables follow the convention VariableName-LevelName. This will allow us to keep track of variable level characteristics, in particular variable importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_enc = ModelTools.CreateDummyVars(dataset,predictors,target,numeric_cat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nearc2-no\n",
      "1 nearc2-yes\n",
      "2 nearc4-no\n",
      "3 nearc4-yes\n",
      "4 nodaded-no\n",
      "5 nodaded-yes\n",
      "6 nomomed-no\n",
      "7 nomomed-yes\n",
      "8 sinmom14-no\n",
      "9 sinmom14-yes\n",
      "10 step14-no\n",
      "11 step14-yes\n",
      "12 black-no\n",
      "13 black-yes\n",
      "14 mar76-2\n",
      "15 mar76-3\n",
      "16 mar76-4\n",
      "17 mar76-5\n",
      "18 mar76-6\n",
      "19 mar76-Null_Value\n",
      "20 mar76-yes\n",
      "21 libcrd14-Null_Value\n",
      "22 libcrd14-no\n",
      "23 libcrd14-yes\n",
      "24 ed76\n",
      "25 ed66\n",
      "26 age76\n",
      "27 daded\n",
      "28 momed\n",
      "29 kww\n",
      "30 iqscore\n",
      "31 exp76\n",
      "32 wage76\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(dataset_enc.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and validation set, with the validation set containing p_val_size (defaulted to 0.2) portion of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "predictors_enc = np.arange(32)\n",
    "target_enc = 32\n",
    " \n",
    "X_train, X_val, Y_train, Y_val = ModelTools.TrainHoldSplit(dataset_enc,predictors_enc,target_enc,p_val_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"random-forest-univariate-analysis\"></a>\n",
    "## Random Forest Univariate Analysis\n",
    "\n",
    "The idea here is to start with all the predictors and iteratively remove one variable at a time, and calculate the loss in overall fit. A larger loss in fit implies a higher marginal importance of the variable. This gives a slightly different perspective than the linear univariate analysis above. Given a group of correlated and highly predictive variables, they will all come through as predictive in the section above since one variable is being fitted at a time, whereas here removing one of these variables should not affect the overall fit too much since the other correlated variables should pick up the lost signal. Here the focus is more on unique contribution of each variable. \n",
    "<br>\n",
    "To avoid over-fitting, p_cross_validations (defaulted to 5) will be used for cross-validation using p_validation_fraction (defaulted to 0.25) for the test set size. In order to reduce run-time, instead of actually removing variables and re-fitting, we will fit the model on the training set and then randomize the variable we would like to remove in order to break any relationship between it and the target variable. This allows us to fit the model once (for each cross-validation set) and infer for each of our predictors instead of re-fitting it for each of our predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Features sorted by their score:*****************\n",
      "ed66: 0.09331\n",
      "kww: 0.03174\n",
      "mar76: 0.03049\n",
      "black: 0.02612\n",
      "iqscore: 0.01461\n",
      "daded: 0.01167\n",
      "ed76: 0.01133\n",
      "momed: 0.00823\n",
      "libcrd14: 0.00599\n",
      "nearc2: 0.00505\n",
      "exp76: 0.00502\n",
      "sinmom14: 0.00148\n",
      "age76: 0.00110\n",
      "nomomed: 0.00078\n",
      "nearc4: 0.00048\n",
      "nodaded: -0.00020\n",
      "step14: -0.00178\n"
     ]
    }
   ],
   "source": [
    "from ModelToolBox.UnivariatePermutations import *\n",
    "from Models.skModels import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "features = ModelTools.FeatureIndexes(dataset, dataset_enc, target_enc)\n",
    "RF_model = sklearn_Model(\"Random Forest\", 'sklearn.ensemble', 'RandomForestRegressor', 'L1')\n",
    "UnivariatePermutations(RF_model, features, X_train, Y_train, p_hyperparams = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"gradient-boosting-univariate-analysis\"></a>\n",
    "## Gradient Boosting Univariate Analysis\n",
    "\n",
    "This section is analagous to the Random Forest Univariate Analysis section above, except using Gradient Boosting models instead of Random Forest models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Features sorted by their score:*****************\n",
      "ed66: 0.08632\n",
      "exp76: 0.05026\n",
      "ed76: 0.04841\n",
      "iqscore: 0.03948\n",
      "kww: 0.03591\n",
      "mar76: 0.02679\n",
      "black: 0.02012\n",
      "daded: 0.01535\n",
      "momed: 0.01295\n",
      "age76: 0.01225\n",
      "sinmom14: 0.00875\n",
      "nearc2: 0.00653\n",
      "libcrd14: 0.00553\n",
      "nearc4: 0.00534\n",
      "step14: 0.00263\n",
      "nodaded: -0.00076\n",
      "nomomed: -0.00195\n"
     ]
    }
   ],
   "source": [
    "GB_model = sklearn_Model(\"Gradient Boosting\", 'sklearn.ensemble', 'GradientBoostingRegressor', 'L1')\n",
    "UnivariatePermutations(GB_model, features, X_train, Y_train, p_hyperparams = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name=\"part-three---variable-selection\"></a>\n",
    "# Part Three - Variable Selection\n",
    "\n",
    "Once a model has been chosen, we need to decide which predictor variables to include. Variable selection will be done using backward and forward stepwise selection. The backward part of this algorithm begins by starting with all, say $n$, predictor variables and iteratively removing one variable at a time and measuring the change in performance. The worst performing variable is then removed from the model. We repeat the process with the $n-1$ remaining variables, again removing the worst performing variable. This continues until all of the remaining variables make a \"significant\" contribution to the model fit. The specific stopping criteria will depend on the problem and metric that is chosen. The forward stepwise selection will then be run (if p_forward = True), by iteratively adding each of the variables that were removed in the backward selection. The most significant, if there any, will be added back to the model. This process continues until none of the remaining variables significantly improve the model.\n",
    "<br>\n",
    "It may not be immediately clear why the forward iteration is useful. The backward (and forward) stepwise selection is a greedy algorithm and may find a local optimum in the feature space. Running the forward iteration will increase the chance of finding the global optimum, however does not guarantee it. Ideally we would compare the model fit on every subset of our preditor variables, however this is computationally expensive with $O(2^n)$ run-time, compared to $O(n^2)$ run-time with the backward/forward selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"random-forest\"></a>\n",
    "## Random Forest\n",
    "\n",
    "Here we run backward and forward stepwise selection with Random Forest models. Similar to the univariate random forest section we will cross-validate using p_cross_validations splits and p_validation_fraction portion of the data in each test set. And again to reduce run-time, instead of removing variables and re-fitting, we will randomize the variable we would like to remove which should have the same effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Variable Performance From Final Backward Iteration:*******\n",
      "ed66: 0.09269\n",
      "kww: 0.03156\n",
      "mar76: 0.03135\n",
      "black: 0.02698\n",
      "iqscore: 0.01285\n",
      "ed76: 0.01154\n",
      "daded: 0.01123\n",
      "momed: 0.00730\n",
      "libcrd14: 0.00604\n",
      "nearc2: 0.00601\n",
      "exp76: 0.00374\n",
      "sinmom14: 0.00163\n",
      "nearc4: 0.00091\n",
      "age76: 0.00065\n",
      "nodaded: 0.00042\n",
      "nomomed: -0.00006\n",
      "****************The optimal set of variables is:*****************\n",
      "nearc2\n",
      "nearc4\n",
      "ed76\n",
      "ed66\n",
      "age76\n",
      "daded\n",
      "nodaded\n",
      "momed\n",
      "sinmom14\n",
      "black\n",
      "kww\n",
      "iqscore\n",
      "mar76\n",
      "libcrd14\n",
      "exp76\n",
      "nomomed\n"
     ]
    }
   ],
   "source": [
    "from ModelToolBox.ForBack import *\n",
    "\n",
    "ForBackPremutations(RF_model, features, predictors_enc, X_train, Y_train, X_val, Y_val, p_hyperparams=250, p_regression=True, p_metric='L1 Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"gradient-boosting\"></a>\n",
    "## Gradient Boosting\n",
    "\n",
    "This section is analagous to the one above, except using gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Variable Performance From Final Backward Iteration:*******\n",
      "ed76: 0.10663\n",
      "ed66: 0.10343\n",
      "exp76: 0.09883\n",
      "kww: 0.09596\n",
      "****************The optimal set of variables is:*****************\n",
      "ed76\n",
      "ed66\n",
      "exp76\n"
     ]
    }
   ],
   "source": [
    "ForBackPremutations(GB_model, features, predictors_enc, X_train, Y_train, X_val, Y_val, p_hyperparams=1000, p_regression=True, p_metric='L1 Error', p_threshold=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
